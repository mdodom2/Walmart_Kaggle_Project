{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walmart Kaggle Project\n",
    "\n",
    "## Authors:  Shijie Wang and Matthew Odom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md              sample_submission.csv  test.csv.zip\r\n",
      "Walmart_Script.ipynb   test.csv               train.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages necessary for computation and load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "\n",
    "# load and prepare the training dataset for modeling\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train = train.dropna()\n",
    "train = train.ix[:, (train.columns != 'FinelineNumber') & (train.columns != 'Upc')]\n",
    "\n",
    "# aggregate ScanCount by DepartmentDescription for each VisitNumber\n",
    "data_1 = train.pivot_table(index = 'VisitNumber', columns = 'DepartmentDescription', values = 'ScanCount', \n",
    "                           aggfunc = np.sum, fill_value=0)\n",
    "data_1['VisitNumber'] = data_1.index\n",
    "\n",
    "# get unique Trip Type, VisitNumber, and Weekday\n",
    "temp = train.drop(train.columns[[3,4]], axis=1)\n",
    "temp = temp.drop_duplicates()\n",
    "\n",
    "train = pd.merge(temp, data_1, on = 'VisitNumber')\n",
    "train = pd.get_dummies(train)\n",
    "\n",
    "\n",
    "\n",
    "# load and prepare the testing dataset for modeling\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test = test.dropna()\n",
    "test = test.ix[:, (test.columns != 'FinelineNumber') & (test.columns != 'Upc')]\n",
    "\n",
    "# aggregate ScanCount by DepartmentDescription for each VisitNumber\n",
    "data_1 = test.pivot_table(index = 'VisitNumber', columns = 'DepartmentDescription', values = 'ScanCount', \n",
    "                           aggfunc = np.sum, fill_value=0)\n",
    "data_1['VisitNumber'] = data_1.index\n",
    "\n",
    "# get unique Trip Type, VisitNumber, and Weekday\n",
    "temp = test.drop(test.columns[[2,3]], axis=1)\n",
    "temp = temp.drop_duplicates()\n",
    "\n",
    "test = pd.merge(temp, data_1, on = 'VisitNumber')\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "X_test = test.ix[:,test.columns != 'VisitNumber']\n",
    "X_test['Intercept'] = 1\n",
    "\n",
    "# a subset for algorithm build\n",
    "#data = train[train[\"TripType\"] <= 10]\n",
    "#data = data.sample(50000)\n",
    "data = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loop for modeling each TripType\n",
    "* Append the results into a submission file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on TripType 999\n",
      "Working on TripType 30\n",
      "Working on TripType 26\n",
      "Working on TripType 8\n",
      "Working on TripType 35\n",
      "Working on TripType 41\n",
      "Working on TripType 21\n",
      "Working on TripType 6\n",
      "Working on TripType 42\n",
      "Working on TripType 7\n",
      "Working on TripType 9\n",
      "Working on TripType 39\n",
      "Working on TripType 25\n",
      "Working on TripType 38\n",
      "Working on TripType 15\n",
      "Working on TripType 36\n",
      "Working on TripType 20\n",
      "Working on TripType 37\n",
      "Working on TripType 32\n",
      "Working on TripType 40\n",
      "Working on TripType 5\n",
      "Working on TripType 3\n",
      "Working on TripType 4\n",
      "Working on TripType 24\n",
      "Working on TripType 33\n",
      "Working on TripType 43\n",
      "Working on TripType 31\n",
      "Working on TripType 27\n",
      "Working on TripType 34\n",
      "Working on TripType 18\n",
      "Working on TripType 29\n",
      "Working on TripType 44\n",
      "Working on TripType 19\n",
      "Working on TripType 23\n",
      "Working on TripType 22\n",
      "Working on TripType 28\n",
      "Working on TripType 14\n",
      "Working on TripType 12\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# create a loop for each TripType\n",
    "# stack the output of the test into single submission\n",
    "TripTypes = data.TripType.unique()\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "for i in TripTypes:\n",
    "    print \"Working on TripType \" + str(i)\n",
    "    \n",
    "    # reset dataset for next iteration\n",
    "    sample = data\n",
    "    sample = sample.dropna()\n",
    "    \n",
    "    # convert independent variable into binary\n",
    "    sample.TripType = np.where(sample.TripType != i, 0, 1) \n",
    "    sample['Intercept'] = 1\n",
    "    \n",
    "    # set up model\n",
    "    X = sample.ix[:,(sample.columns != 'TripType') & (sample.columns != 'VisitNumber') & (sample.columns != 'HEALTH AND BEAUTY AIDS')]\n",
    "    y = sample.ix[:,sample.columns == 'TripType']\n",
    "    \n",
    "    model = sm.OLS(y,X)\n",
    "    results = model.fit()\n",
    "    #results.summary()\n",
    "    \n",
    "    # predict test dataset values\n",
    "    yhat = pd.DataFrame(results.predict(X_test)) # this should be results.predict(test)\n",
    "    yhat.columns = [\"TripType_%s\" % i]\n",
    "    \n",
    "    # append columns to submission\n",
    "    submission = submission.join(yhat, how = \"outer\")\n",
    "    \n",
    "print \"All done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the submission file \n",
    "* replace the highest likelihood with one\n",
    "* join with the VisitNumber for Kaggle evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = submission.sort_index(axis=1)\n",
    "submission = submission.apply(lambda row: np.where(row == max(row), 1, 0), axis = 1)\n",
    "submission = pd.DataFrame(test['VisitNumber']).join(submission)\n",
    "submission.to_csv(\"WalmartKaggleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                    test.csv\r\n",
      "WalmartKaggleSubmission.csv  test.csv.zip\r\n",
      "Walmart_Script.ipynb         train.csv\r\n",
      "sample_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
